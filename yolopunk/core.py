# YOLOPunk ü©∏ AGPL-3.0 License

"""M√≥dulo core do YOLOPunk.

Cont√©m a classe Vision, interface principal para detec√ß√£o de objetos.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any

try:
    from ultralytics import YOLO

    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    YOLO = None


class Vision:
    """Interface principal do YOLOPunk para detec√ß√£o de objetos.

    Esta classe encapsula a funcionalidade YOLO, fornecendo uma API simplificada e consistente para detec√ß√£o,
    segmenta√ß√£o e tracking.

    Args:
        model: Gnome do modelo YOLO ou caminho para arquivo de pesos.
        Ex: 'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', etc.
        device: Device para infer√™ncia. Op√ß√µes:
                - 'cuda': GPU NVIDIA
                - 'cpu': CPU
                - 'mps': Apple Silicon GPU
                - None: Auto-detect
        task: Tipo de tarefa. Op√ß√µes:
              - 'detect': Detec√ß√£o de objetos (padr√£o)
              - 'segment': Segmenta√ß√£o de inst√¢ncias
              - 'pose': Estima√ß√£o de pose
              - 'classify': Classifica√ß√£o
        verbose: Se True, exibe logs do YOLO.

    Attributes:
        model_name: Gnome ou caminho do modelo.
        device: Device utilizado.
        task: Tarefa configurada.
        model: Inst√¢ncia do modelo YOLO (None se n√£o carregado).

    Examples:
        >>> # Detec√ß√£o b√°sica
        >>> detector = Vision("yolov8n.pt")
        >>> results = detector.detect("image.jpg")

        >>> # Detec√ß√£o com GPU
        >>> detector = Vision("yolov8n.pt", device="cuda")
        >>> results = detector.detect("image.jpg", conf=0.5)

        >>> # Segmenta√ß√£o
        >>> segmenter = Vision("yolov8n-seg.pt", task="segment")
        >>> results = segmenter.detect("image.jpg")
    """

    def __init__(
        self,
        model: str = "yolov8n.pt",
        device: str | None = None,
        task: str = "detect",
        verbose: bool = False,
    ):
        """Inicializa o detector Vision."""
        if not ULTRALYTICS_AVAILABLE:
            raise ImportError("Ultralytics YOLO n√£o est√° instalado. Install com: pip install ultralytics")

        self.model_name = model
        self.device = device or self._auto_detect_device()
        self.task = task
        self.verbose = verbose
        self._model: YOLO | None = None

    def _auto_detect_device(self) -> str:
        """Detecta automaticamente o melhor device dispon√≠vel.

        Returns:
            'cuda', 'mps', ou 'cpu'
        """
        import torch

        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            return "mps"
        return "cpu"

    @property
    def model(self) -> YOLO:
        """Lazy loading do modelo YOLO.

        O modelo s√≥ √© carregado quando acessado pela primeira vez.

        Returns:
            Inst√¢ncia do modelo YOLO.
        """
        if self._model is None:
            self._model = YOLO(self.model_name, task=self.task)
            if self.verbose:
                print(f"ü©∏ Modelo carregado: {self.model_name}")
                print(f"ü©∏ Device: {self.device}")
        return self._model

    def detect(
        self,
        source: str | Path | list,
        conf: float = 0.25,
        iou: float = 0.7,
        max_det: int = 300,
        classes: list[int] | None = None,
        save: bool = False,
        save_txt: bool = False,
        save_conf: bool = False,
        **kwargs: Any,
    ) -> Any:
        """Realiza detec√ß√£o de objetos em imagem(ns) ou v√≠deo.

        Args:
            source: Caminho para imagem, v√≠deo, diret√≥rio ou lista de caminhos. Tamb√©m aceita URLs, streams, webcam (0,
                1, etc.).
            conf: Threshold de confian√ßa (0.0-1.0). Padr√£o: 0.25
            iou: Threshold de IoU para NMS. Padr√£o: 0.7
            max_det: N√∫mero m√°ximo de detec√ß√µes por imagem. Padr√£o: 300
            classes: Lista de IDs de classes para filtrar. Ex: [0, 1, 2]
            save: Se True, salva imagens com anota√ß√µes.
            save_txt: Se True, salva resultados em formato texto.
            save_conf: Se True, inclui confian√ßa nos arquivos texto.
            **kwargs: Arguments adicionais para model.predict()

        Returns:
            Resultados da detec√ß√£o (ultralytics.engine.results.Results)

        Examples:
            >>> # Detec√ß√£o b√°sica
            >>> results = detector.detect("image.jpg")

            >>> # Detec√ß√£o com threshold alto
            >>> results = detector.detect("image.jpg", conf=0.7)

            >>> # Detectar apenas pessoas (classe 0 no COCO)
            >>> results = detector.detect("image.jpg", classes=[0])

            >>> # Processar m√∫ltiplas imagens
            >>> results = detector.detect(["img1.jpg", "img2.jpg"])

            >>> # Webcam
            >>> results = detector.detect(0, stream=True)
        """
        results = self.model.predict(
            source=source,
            conf=conf,
            iou=iou,
            max_det=max_det,
            classes=classes,
            save=save,
            save_txt=save_txt,
            save_conf=save_conf,
            device=self.device,
            verbose=self.verbose,
            **kwargs,
        )
        return results

    def train(
        self,
        data: str,
        epochs: int = 100,
        imgsz: int = 640,
        batch: int = 16,
        **kwargs: Any,
    ) -> Any:
        """Treina o modelo YOLO com dataset customizado.

        Args:
            data: Caminho para arquivo YAML de configura√ß√£o do dataset.
            epochs: N√∫mero de √©pocas de treinamento.
            imgsz: Tamanho da imagem de entrada.
            batch: Tamanho do batch.
            **kwargs: Arguments adicionais para model.train()

        Returns:
            Resultados do treinamento.

        Examples:
            >>> detector = Vision("yolov8n.pt")
            >>> results = detector.train(data="dataset.yaml", epochs=50, imgsz=640, batch=16)
        """
        results = self.model.train(
            data=data,
            epochs=epochs,
            imgsz=imgsz,
            batch=batch,
            device=self.device,
            **kwargs,
        )
        return results

    def export(
        self,
        format: str = "onnx",
        **kwargs: Any,
    ) -> str:
        """Exporta o modelo para outros formatos.

        Args:
            format: Formato de exporta√ß√£o. Op√ß√µes: 'onnx', 'torchscript', 'coreml', 'tflite', etc.
            **kwargs: Arguments adicionais para model.export()

        Returns:
            Caminho do arquivo exportado.

        Examples:
            >>> detector = Vision("yolov8n.pt")
            >>> path = detector.export(format="onnx")
        """
        path = self.model.export(format=format, **kwargs)
        if self.verbose:
            print(f"ü©∏ Modelo exportado: {path}")
        return path

    def benchmark(
        self,
        **kwargs: Any,
    ) -> dict:
        """Realiza benchmark de performance do modelo.

        Args:
            **kwargs: Arguments adicionais para model.benchmark()

        Returns:
            Dicion√°rio com m√©tricas de performance.

        Examples:
            >>> detector = Vision("yolov8n.pt")
            >>> metrics = detector.benchmark()
        """
        return self.model.benchmark(**kwargs)

    def __repr__(self) -> str:
        """Representa√ß√£o string do objeto."""
        return f"Vision(model={self.model_name!r}, device={self.device!r}, task={self.task!r})"

    def __str__(self) -> str:
        """String leg√≠vel do objeto."""
        return f"YOLOPunk Vision - {self.model_name} on {self.device}"
